
# âš ï¸ **IMPORTANTE: Entorno de ejecuciÃ³n de los comandos**

ğŸ”¹ **La documentaciÃ³n actual usa sintaxis y herramientas nativas de Linux**, como `bash`, `export`, `chmod`, y comandos de AWS CLI.  
ğŸ”¹ **EstÃ¡ optimizada para ejecutarse en AWS (EC2, EFS, Lambda) o en una terminal Linux/Mac.**  
ğŸ”¹ **No estÃ¡ diseÃ±ada para ejecutarse en Windows CMD o PowerShell directamente.**  

---

## ğŸ–¥ï¸ **Ejecutar comandos desde Windows para gestionar el despliegue en AWS**

Si usas Windows y necesitas gestionar el despliegue en AWS, sigue estas instrucciones:  

### ğŸ”¹ **1. Instalar AWS CLI en Windows**
1ï¸âƒ£ Descarga e instala [AWS CLI para Windows](https://aws.amazon.com/cli/).  
2ï¸âƒ£ Abre **PowerShell** como administrador.  
3ï¸âƒ£ Configura las credenciales de AWS con:  
   ```powershell
   aws configure
   ```

### ğŸ”¹ **2. Usar PowerShell para exportar variables de entorno**  
ğŸ’¡ En Linux usamos `export`, en PowerShell se usa `$env:`  

**Ejemplo en Linux:**  
```sh
export AWS_ACCESS_KEY_ID="TU_ACCESS_KEY"
export AWS_SECRET_ACCESS_KEY="TU_SECRET_KEY"
```

**Equivalente en Windows PowerShell:**  
```powershell
$env:AWS_ACCESS_KEY_ID="TU_ACCESS_KEY"
$env:AWS_SECRET_ACCESS_KEY="TU_SECRET_KEY"
```

### ğŸ”¹ **3. Ejecutar GitHub Actions desde Windows**  
Los workflows de GitHub Actions no dependen del sistema operativo, pero puedes iniciarlos manualmente desde Windows con:  
```powershell
gh workflow run deploy.yml
```

---

âœ… **Con esto, puedes gestionar el despliegue en AWS desde Windows sin necesidad de cambiar la infraestructura a Windows.**


# ğŸš€ **GuÃ­a de Despliegue con AWS y GitHub Actions**

Esta secciÃ³n describe **paso a paso** cÃ³mo desplegar Medical-RAGArch-System en **AWS Lambda** y **DynamoDB** utilizando **GitHub Actions**.

## ğŸ“Œ **1ï¸âƒ£ Resumen del Despliegue**

| **Paso** | **AcciÃ³n** | **Detalles** |
|----------|-----------|-------------|
| 1ï¸âƒ£ | **Crear Cuenta AWS** | [Crear cuenta en AWS](https://aws.amazon.com/) |
| 2ï¸âƒ£ | **Configurar IAM** | [Configurar IAM y credenciales](https://docs.aws.amazon.com/IAM/) |
| 3ï¸âƒ£ | **Configurar AWS CLI** | `aws configure` |
| 4ï¸âƒ£ | **Agregar Credenciales en GitHub** | Configurar `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION` |
| 5ï¸âƒ£ | **Ejecutar GitHub Actions** | Orden de ejecuciÃ³n recomendado |
| 6ï¸âƒ£ | **Verificar en AWS Lambda** | Confirmar despliegue en [AWS Lambda](https://console.aws.amazon.com/lambda) |
| 7ï¸âƒ£ | **Acceder a la API** | API Gateway en AWS |

## ğŸ“Œ **2ï¸âƒ£ ConfiguraciÃ³n de AWS**
### ğŸ”¹ **1. Crear Cuenta y Configurar IAM**
1ï¸âƒ£ Crear una cuenta en [AWS](https://aws.amazon.com/).  
2ï¸âƒ£ Ir a [IAM](https://console.aws.amazon.com/iam) y generar una **Access Key** y **Secret Key**.  
3ï¸âƒ£ Agregar los permisos necesarios para **Lambda**, **DynamoDB** y **API Gateway**.  

### ğŸ”¹ **2. Configurar AWS CLI**
Ejecutar en la terminal:
```sh
aws configure
```
Ingresar las credenciales de AWS generadas en IAM.

## ğŸ“Œ **3ï¸âƒ£ ConfiguraciÃ³n de GitHub Actions**

### ğŸ”¹ **1. Agregar Credenciales en GitHub Secrets**
1ï¸âƒ£ Ir a **GitHub > Settings > Secrets and variables > Actions**.  
2ï¸âƒ£ Agregar las siguientes credenciales:  
   - `AWS_ACCESS_KEY_ID`
   - `AWS_SECRET_ACCESS_KEY`
   - `AWS_REGION`  

### ğŸ”¹ **2. Orden de EjecuciÃ³n de Workflows**
Ejecutar los workflows en este orden:

1ï¸âƒ£ **`setup_efs_vpc.yml`** â†’ Configura AWS EFS y la VPC necesaria.  
2ï¸âƒ£ **`deploy_lambda_layers.yml`** â†’ Sube dependencias a AWS Lambda Layers.  
3ï¸âƒ£ **`deploy_with_secrets.yml`** â†’ Configura IAM y Secrets Manager.  
4ï¸âƒ£ **`deploy.yml`** â†’ Despliega la API en AWS Lambda.  
5ï¸âƒ£ **`run_tests.yml`** â†’ Ejecuta pruebas para validar el despliegue.  

## ğŸ“Œ **4ï¸âƒ£ VerificaciÃ³n del Despliegue**
1ï¸âƒ£ Ir a **[AWS Lambda](https://console.aws.amazon.com/lambda)** y verificar que la funciÃ³n `"MedicalRAG"` estÃ¡ creada.  
2ï¸âƒ£ Revisar **[DynamoDB](https://console.aws.amazon.com/dynamodb)** y confirmar que la tabla `"MedicalData"` existe.  
3ï¸âƒ£ Acceder a **[API Gateway](https://console.aws.amazon.com/apigateway)** y probar los endpoints.

âœ… **Listo. El sistema estÃ¡ desplegado y operativo en AWS.**  

# ğŸš€ Medical-RAGArch-System

âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.


---



### ğŸ“Œ Estado de las Optimizaciones Documentadas
Se confirma que las siguientes optimizaciones mencionadas en el README **ya estÃ¡n implementadas en el sistema**:

âœ… **DAX en DynamoDB activado:** `aws/enable_dax.py`  
âœ… **Auto Scaling en DynamoDB activado:** `aws/enable_adaptive_capacity.py`  
âœ… **SnapStart en AWS Lambda activado:** `aws/lambda_snapstart.py`  
âœ… **OCR AutomÃ¡tico habilitado:** `modules/ocr/ocr_advanced.py`  
âœ… **OptimizaciÃ³n de Redis Cloud implementada:** `modules/cache/cache_redis.py`  

No es necesario realizar cambios adicionales en estos aspectos.  

## ğŸ” **AutenticaciÃ³n y Seguridad**
Para proteger las herramientas expuestas a ChatGPT, se han implementado:
âœ… **AutenticaciÃ³n con  y API Keys generadas dinÃ¡micamente.**  
âœ… **ProtecciÃ³n con firma HMAC en cada solicitud.**  
âœ… **Cifrado TLS en API Gateway de AWS.**  
âœ… **RestricciÃ³n de llamadas en AWS Lambda a solicitudes autenticadas.**  

ğŸ“Œ **UbicaciÃ³n de los archivos de seguridad:**
| Archivo | UbicaciÃ³n en el Proyecto |
|---------|-------------------------|
| `fastapi_authentication.py` | `api/security/fastapi_authentication.py` |
| `aws_api_gateway_flexible.tf` | `infrastructure/aws/terraform/aws_api_gateway_flexible.tf` |
| `aws_lambda_secure_invocation.tf` | `infrastructure/aws/terraform/aws_lambda_secure_invocation.tf` |

---

## ğŸ¤– **IA Compatibles y MÃ©todos de IntegraciÃ³n**

El sistema puede integrarse con **cualquier IA que soporte API HTTP o WebSockets**.  
Ejemplos de integraciÃ³n con modelos populares:

ğŸ“Œ **CÃ³mo Integrarlo:**  
```python
    model="gpt-4",
    messages=[{"role": "system", "content": "Analiza este documento mÃ©dico"}],
    REMOVED_SECRET
)
```

---

### **2ï¸âƒ£ Hugging Face Transformers (Modelos NLP en Local o en la Nube)**
ğŸ“Œ **CÃ³mo Integrarlo:**  
```python
from transformers import pipeline
summarizer = pipeline("summarization")
summary = summarizer("Este es un texto largo que quiero resumir.")
```

---

### **3ï¸âƒ£ Stable Diffusion (GeneraciÃ³n de ImÃ¡genes MÃ©dicas)**
ğŸ“Œ **CÃ³mo Integrarlo:**  
```python
import requests
response = requests.post("https://stablediffusion.api/imagen", json={"prompt": "RadiografÃ­a de tÃ³rax con neumonÃ­a"})
```

---

### **4ï¸âƒ£ API de IA MÃ©dicas Especializadas (IBM Watson, MedPaLM 2, BioGPT)**
ğŸ“Œ **CÃ³mo Integrarlo:**  
```python
response = requests.post("https://biogpt.api/med-query", json={"query": "Efectos de la metformina en resistencia a la insulina"})
```

---

## ğŸ”„ **Despliegue Automatizado en AWS**
Todos los componentes del sistema se despliegan automÃ¡ticamente con **GitHub Actions** y **Terraform**, sin intervenciÃ³n manual.

ğŸ“Œ **Workflows Configurados:**
| Workflow | FunciÃ³n |
|----------|--------|
| `deploy.yml` | Despliega la API en AWS Lambda |
| `update_prompts.yml` | Sincroniza los prompts |
| `deploy_with_secrets.yml` | Configura variables de entorno automÃ¡ticamente |

ğŸ“Œ **EjecuciÃ³n AutomÃ¡tica:**  
```bash
git push origin main  # Despliega automÃ¡ticamente en AWS
```

---

## ğŸ“„ **Instrucciones para Usuarios No TÃ©cnicos**
1ï¸âƒ£ **Ejecutar el despliegue con GitHub Actions** (sin comandos manuales).  
2ï¸âƒ£ **Conectarse a ChatGPT usando API Keys generadas automÃ¡ticamente**.  
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

4ï¸âƒ£ **El sistema maneja toda la seguridad de forma transparente.**  




# Medical-RAGArch-System

## ğŸ“Œ Â¿QuÃ© es este proyecto?
Medical-RAGArch-System es un sistema de **IA aplicada a documentos mÃ©dicos**, que permite:
- **Almacenar, procesar y recuperar informaciÃ³n estructurada** de documentos mÃ©dicos.
- **Optimizar la infraestructura en la nube con AWS Lambda y DynamoDB**.
- **Automatizar despliegues y mantenimiento** con GitHub Actions y AWS CDK.

Esta versiÃ³n incluye mejoras clave en rendimiento, seguridad y escalabilidad.



## ğŸ”¹ 1ï¸âƒ£ Procesos Totalmente Automatizados


# ğŸš€ IntegraciÃ³n con AWS (Lambda, DynamoDB, API Gateway)

Este proyecto utiliza mÃºltiples servicios de **AWS** para mejorar su rendimiento, escalabilidad y disponibilidad.

## ğŸ“Œ **Servicios Utilizados**

| Servicio      | FunciÃ³n en el Proyecto |
|--------------|------------------------|
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

| **DynamoDB** | Base de datos NoSQL optimizada para respuestas rÃ¡pidas |
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

| **SnapStart** | Reduce los tiempos de arranque de Lambda |
| **DAX** | Acelera las consultas en DynamoDB |

## âš™ï¸ **ConfiguraciÃ³n Manual en AWS**
Si deseas configurar manualmente los servicios en AWS, sigue estos pasos:

### **1ï¸âƒ£ Configurar AWS Lambda**
```bash
aws lambda create-function --function-name MedicalRAG --runtime python3.8 --role <IAM_ROLE> --handler api.main.lambda_handler
```

### **2ï¸âƒ£ Configurar DynamoDB**
```bash
aws dynamodb create-table --table-name MedicalData --attribute-definitions AttributeName=id,AttributeType=S --key-schema AttributeName=id,KeyType=HASH --billing-mode PAY_PER_REQUEST
```

---

## ğŸ› ï¸ **ConfiguraciÃ³n AutomÃ¡tica con CDK**
Si prefieres desplegarlo automÃ¡ticamente, usa los scripts de `aws/`:
```bash
cd aws/
python enable_dax.py  # Activa DAX en DynamoDB
python lambda_snapstart.py  # Habilita SnapStart en AWS Lambda
```




Estos procesos se ejecutan sin intervenciÃ³n manual una vez configurados:

| **Funcionalidad** | **AutomatizaciÃ³n** | **ExplicaciÃ³n** |
|--------------|-------------|-------------|
| **Carga y procesamiento de documentos** | âœ… SÃ­ | El sistema detecta automÃ¡ticamente el tipo de documento y lo procesa. |
| **OCR automÃ¡tico** | âœ… SÃ­ | Si el documento es una imagen escaneada, el OCR se activa sin necesidad de ajuste manual. |
| **OptimizaciÃ³n de consultas con Redis** | âœ… SÃ­ | Las consultas repetidas se almacenan en cachÃ© para reducir la carga en DynamoDB. |
| **Despliegue en AWS Lambda y DynamoDB con GitHub Actions** | âœ… SÃ­ | El cÃ³digo se actualiza y despliega automÃ¡ticamente sin intervenciÃ³n. |
| **Auto Scaling en DynamoDB** | âœ… SÃ­ | Se ajusta la capacidad de la base de datos segÃºn la demanda del sistema. |
| **GeneraciÃ³n de respuestas estructuradas para ChatGPT** | âœ… SÃ­ | Las respuestas son resumidas y formateadas automÃ¡ticamente antes de enviarlas. |

---

## ğŸ”¹ 2ï¸âƒ£ Procesos que Requieren ConfiguraciÃ³n Manual


# ğŸš€ OptimizaciÃ³n con Redis y Numba

Este proyecto utiliza **Redis Cloud** y **Numba** para mejorar el rendimiento en tiempo de respuesta y cÃ¡lculos intensivos.

## ğŸ“Œ **OptimizaciÃ³n con Redis**

Redis se usa para **cachear respuestas frecuentes**, reduciendo la carga en DynamoDB.

### **ğŸ“Œ ConfiguraciÃ³n Manual de Redis**
1ï¸âƒ£ Crea un clÃºster de Redis en AWS o usa una instancia local.  
2ï¸âƒ£ Configura el archivo `config/redis_config.py` con las credenciales:

```python
REDIS_HOST = "redis-cluster.amazonaws.com"
REDIS_PORT = 6379
REDIS_REMOVED_SECRET
```

### **ğŸ“Œ Uso en el CÃ³digo**
```python
import redis

cache = redis.StrictRedis(host=REDIS_HOST, port=REDIS_PORT, password=REDIS_PASSWORD, decode_responses=True)
cache.set("consulta_usuario", resultado_procesado, ex=3600)  # Cache por 1 hora
```

---

## âš¡ **OptimizaciÃ³n con Numba**
Numba acelera cÃ¡lculos de Machine Learning y NLP optimizando operaciones matemÃ¡ticas intensivas.

### **ğŸ“Œ Ejemplo de Uso**
```python
from numba import jit

@jit(nopython=True)
def calcular_metricas(datos):
    return sum(datos) / len(datos)
```




Algunas funciones necesitan intervenciÃ³n manual para ajustarse a escenarios especÃ­ficos:

| **Funcionalidad** | **IntervenciÃ³n Manual** | **Motivo** |
|--------------|-------------|-------------|
| **Ajuste de umbral en OCR** | âš ï¸ SÃ­ | Dependiendo de la calidad de la imagen, puede ser necesario ajustar la precisiÃ³n del OCR. |
| **PolÃ­ticas de retenciÃ³n de datos en DynamoDB** | âš ï¸ SÃ­ | Por defecto, los datos se almacenan indefinidamente, pero pueden configurarse reglas de expiraciÃ³n. |
| **ModificaciÃ³n del NLP para respuestas mÃ¡s detalladas o resumidas** | âš ï¸ SÃ­ | Se puede modificar el nivel de resumen en el modelo de NLP. |
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

| **Seguridad y autenticaciÃ³n avanzada** | âš ï¸ SÃ­ | Si se necesita una capa extra de seguridad, se pueden modificar los mÃ©todos de autenticaciÃ³n. |



## ğŸ”¹ 3ï¸âƒ£ Casos PrÃ¡cticos para Diferentes Niveles de AutomatizaciÃ³n


# ğŸ¤– Modelos de Machine Learning y NLP

El sistema incluye modelos de **predicciÃ³n y procesamiento de lenguaje natural (NLP)** para analizar documentos mÃ©dicos.

## ğŸ“Œ **Modelos Implementados**
| MÃ³dulo | Funcionalidad |
|--------|--------------|
| **ml_models.py** | Modelos de predicciÃ³n y clasificaciÃ³n |
| **intelligent_context.py** | Procesamiento avanzado de lenguaje natural |
| **time_series.py** | Predicciones basadas en series temporales |

---

## âš™ï¸ **CÃ³mo Personalizar los Modelos**

### **Modificar ParÃ¡metros del Modelo NLP**
Edita el archivo `config/nlp_config.json`:
```json
{
    "max_length": 500,
    "min_length": 200,
    "do_sample": true
}
```

### **Ejemplo de Uso en el CÃ³digo**
```python
from transformers import pipeline

summarizer = pipeline("summarization", max_length=500, min_length=200, do_sample=True)
```




### **Escenario 1: Uso estÃ¡ndar con automatizaciÃ³n total**  
ğŸ”¹ **Tienes documentos en AWS S3 y deseas analizarlos automÃ¡ticamente.**  
âœ… **SoluciÃ³n:** Configura una regla en AWS Lambda para que procese cualquier archivo nuevo automÃ¡ticamente.  

```json
{
  "source": "AWS-S3",
  "processing_mode": "AUTO"
}
```

---

### **Escenario 2: Seguridad Avanzada y RetenciÃ³n de Datos**  
ğŸ”¹ **Requieres mayor control sobre los tiempos de expiraciÃ³n de los documentos.**  
âœ… **SoluciÃ³n:** Configura polÃ­ticas de retenciÃ³n en DynamoDB y habilita autenticaciÃ³n avanzada con .  

```bash
export TOKEN_EXPIRATION=3600  # ExpiraciÃ³n de tokens en 1 hora
```

---

### **Escenario 3: Activar WebSockets para Consultas en Tiempo Real**  
ğŸ”¹ **Quieres que ChatGPT pueda obtener respuestas sin esperar consultas HTTP tradicionales.**  
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.


```bash
uvicorn api.main:app --host 0.0.0.0 --port 8000 --ws
```



## ğŸ”¹ InteracciÃ³n con CÃ³digo Python y Comandos Bash


# ğŸ”„ Despliegue con GitHub Actions

El sistema tiene **workflows automÃ¡ticos** para desplegar en AWS.

## ğŸ“Œ **Workflows Disponibles**
| Workflow | FunciÃ³n |
|----------|--------|
| `deploy.yml` | Despliega la API en AWS Lambda |
| `update_prompts.yml` | Sincroniza los prompts |
| `deploy_with_secrets.yml` | Configura variables de entorno automÃ¡ticamente |

### **ğŸ“Œ CÃ³mo Ejecutar un Despliegue**
```bash
git push origin main  # Esto activarÃ¡ el workflow de GitHub Actions automÃ¡ticamente
```




Medical-RAGArch-System permite ajustar configuraciones y ejecutar acciones a travÃ©s de cÃ³digo Python y comandos Bash.

---

### ğŸ”¹ **Uso de CÃ³digo Python**

âœ” **Los fragmentos de cÃ³digo Python ya estÃ¡n implementados en el sistema.**  
âœ” **Solo necesitas modificarlos si deseas personalizar la configuraciÃ³n.**  
âœ” **Si un archivo especÃ­fico es mencionado (`api/main.py`, `nlp_config.py`), edÃ­talo ahÃ­.**  

ğŸ“Œ **Ejemplo de ajuste en Python (modificar en `nlp_config.py`)**  
```python
summarizer = pipeline('summarization', max_length=500, min_length=250, do_sample=True)
```

ğŸ“Œ **Otros ejemplos de cÃ³digo en Python utilizados en diferentes secciones:**  

- **WebSockets:** ComunicaciÃ³n en tiempo real con consultas optimizadas.  
- **OCR con OpenCV:** Mejora de precisiÃ³n en documentos escaneados.  
- **OptimizaciÃ³n de cachÃ© con Redis:** Acelerar consultas frecuentes.  

---

### ğŸ”¹ **Uso de Comandos Bash**

âœ” **Se ejecutan en la terminal (Linux/macOS o AWS CloudShell).**  
âœ” **NO debes pegarlos dentro del cÃ³digo del proyecto.**  
âœ” **Se usan para configurar AWS Lambda, Redis o DynamoDB manualmente.**  

ğŸ“Œ **Ejemplo de comando Bash (ejecutar en la terminal)**  
```bash
aws lambda update-function-configuration --function-name MedicalRAG --memory-size 2048
```

ğŸ“Œ **Otros comandos Ãºtiles:**  

- **Configurar OCR avanzado en AWS Lambda**  
- **Habilitar SnapStart para mejorar tiempos de ejecuciÃ³n**  
- **Ajustar escalado automÃ¡tico en DynamoDB**  



## ğŸ”¹ 5ï¸âƒ£ Restaurar la ExplicaciÃ³n sobre AWS Lambda SnapStart y DAX


# ğŸ” Seguridad con AES-256 y 

Este proyecto protege la informaciÃ³n mediante **cifrado AES-256** y **autenticaciÃ³n con **.

## ğŸ“Œ **Cifrado AES-256**
Se usa para proteger datos sensibles en bases de datos y en transmisiÃ³n.

### **ğŸ“Œ Ejemplo de EncriptaciÃ³n**
```python
from Crypto.Cipher import AES

cipher = AES.new(key, AES.MODE_GCM)
ciphertext, tag = cipher.encrypt_and_digest(data)
```

---

## ğŸ› ï¸ **GestiÃ³n de Tokens **
Se usa  para manejar sesiones y autenticaciÃ³n.

### **ğŸ“Œ Crear un Token **
```python
âœ… **Sistema de Seguridad Actualizado:**
-  ha sido **totalmente eliminado** y reemplazado por Zero Trust Architecture (ZTA).
- La autenticaciÃ³n y seguridad ahora se gestionan a travÃ©s de identidades y accesos controlados dinÃ¡micamente.


âœ… **Sistema de Seguridad Actualizado:**
-  ha sido **totalmente eliminado** y reemplazado por Zero Trust Architecture (ZTA).
- La autenticaciÃ³n y seguridad ahora se gestionan a travÃ©s de identidades y accesos controlados dinÃ¡micamente.

```




ğŸ“Œ **ConfiguraciÃ³n Manual Necesaria**:  
1. **Configurar Subnet Group en AWS Console** para que el clÃºster pueda operar.  
2. **Agregar Security Groups si es necesario**, segÃºn la arquitectura de red de AWS.  
3. **Actualizar la configuraciÃ³n de la aplicaciÃ³n para conectarse a DAX en vez de DynamoDB directamente.**  

### **ActivaciÃ³n Manual de AWS Lambda SnapStart**
- **SnapStart reduce el tiempo de arranque de Lambda** y mejora la latencia.
- **Debe activarse manualmente en la consola de AWS**, ya que AWS no permite su activaciÃ³n automÃ¡tica desde CDK.

ğŸ“Œ **Pasos para activarlo**:
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

2. En la pestaÃ±a **ConfiguraciÃ³n**, buscar la opciÃ³n **SnapStart** y activarla.
3. Guardar los cambios y probar la ejecuciÃ³n.


# âš™ï¸ Configuraciones Avanzadas y PersonalizaciÃ³n en Medical-RAGArch-System

Medical-RAGArch-System permite ajustar mÃºltiples configuraciones para **optimizar rendimiento, mejorar seguridad y personalizar la experiencia del usuario**.

âœ… **Ajustes de rendimiento en AWS Lambda, Redis y DynamoDB.**  
âœ… **PersonalizaciÃ³n de respuestas NLP y procesamiento de documentos.**  
âœ… **Modificaciones en seguridad, autenticaciÃ³n y cifrado.**  
âœ… **OptimizaciÃ³n exclusiva para `aarch64` (no compatible con Windows).**  
âœ… **Configuraciones automatizadas vs. ajustes manuales.**  

---

## ğŸ”¹ 1ï¸âƒ£ ParÃ¡metros Ajustables para Optimizar el Sistema

| **ConfiguraciÃ³n** | **DescripciÃ³n** | **Valor Predeterminado** | **AutomÃ¡tico** |
|------------------|----------------|-----------------|------------|
| `AWS Lambda Memory` | Ajusta la memoria para mejorar rendimiento en consultas. | 1024 MB | âœ… SÃ­ |
| `DynamoDB Capacity` | Modifica el escalado automÃ¡tico de la base de datos. | Auto Scaling | âœ… SÃ­ |
| `OCR Precision` | Ajusta la sensibilidad de detecciÃ³n en imÃ¡genes escaneadas. | 0.85 | âš ï¸ Manual |
| `WebSockets Timeouts` | Cambia el tiempo de espera en comunicaciÃ³n en tiempo real. | 30 seg | âœ… SÃ­ |
| `Cache Expiry` | Ajusta la expiraciÃ³n de cachÃ© en Redis para optimizar respuestas. | 1 hora | âœ… SÃ­ |
| `NLP Summary Length` | Controla la longitud de los resÃºmenes generados por NLP. | 250 palabras | âš ï¸ Manual |

ğŸ“Œ **Notas**:  
- **Redis ya estÃ¡ habilitado y configurado, solo requiere ajustes si se necesita un mayor control.**  
- **AWS Lambda SnapStart estÃ¡ activado para reducir tiempos de inicio en frÃ­o.**  
- **Este sistema estÃ¡ optimizado exclusivamente para `aarch64` y no funciona en Windows.**  

---

âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.


### **ğŸ“Œ Ajustar Permisos CORS y Seguridad**
Si necesitas restringir accesos externos:

```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://mi-sitio.com"],
    allow_methods=["GET", "POST"],
    allow_headers=["Authorization"],
)
```

ğŸ“Œ **Consejo:** **Nunca permitas `allow_origins=["*"]` en producciÃ³n** para evitar ataques.

### **ğŸ“Œ Habilitar WebSockets para Consultas en Tiempo Real**
WebSockets ya estÃ¡n habilitados y optimizados, pero puedes ajustar parÃ¡metros si es necesario:

```python
WEBSOCKET_TIMEOUT = 20  # Reducir tiempo de espera para respuestas mÃ¡s rÃ¡pidas
```

ğŸ“Œ **Ventajas:**  
âœ… **Permite respuestas inmediatas sin mÃºltiples peticiones HTTP.**  
âœ… **Reduce la latencia de consultas en ChatGPT.**  

---

## ğŸ”¹ 3ï¸âƒ£ PersonalizaciÃ³n de Respuestas NLP y Procesamiento de Documentos

Si deseas que las respuestas sean mÃ¡s detalladas o mÃ¡s concisas, puedes ajustar:

```python
summarizer = pipeline('summarization', model="facebook/bart-large-cnn", max_length=500, min_length=250, do_sample=True)
```

ğŸ“Œ **Opciones avanzadas:**  
- **ResÃºmenes concisos** â†’ `max_length = 150`.  
- **Respuestas detalladas** â†’ `max_length = 800`.  

ğŸ“Œ **OCR ya estÃ¡ habilitado**, pero puedes mejorar la precisiÃ³n con preprocesamiento de imÃ¡genes en OpenCV:

```python
image = cv2.imread("documento.jpg")
image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
image = cv2.GaussianBlur(image, (5,5), 0)
```

---

## ğŸ”¹ 4ï¸âƒ£ OptimizaciÃ³n de Rendimiento en AWS Lambda y DynamoDB


# ğŸ“„ OCR Avanzado y ValidaciÃ³n de Suplementos

El sistema tiene **OCR mejorado** para procesar documentos escaneados y **valida interacciones entre suplementos mÃ©dicos**.

## ğŸ“Œ **OCR Mejorado**
El mÃ³dulo `ocr_advanced.py` mejora el reconocimiento de texto en imÃ¡genes de baja calidad.

### **ğŸ“Œ Ejemplo de Uso**
```python
from utils.ocr import procesar_imagen

texto_extraido = procesar_imagen("documento.jpg")
```

---

## ğŸ§ª **ValidaciÃ³n de Interacciones entre Suplementos**
El archivo `supplement_validation.yaml` contiene reglas para verificar combinaciones peligrosas.

### **ğŸ“Œ Ejemplo de ValidaciÃ³n**
```python
from modules.supplement_interaction_validation import validar_interaccion

resultado = validar_interaccion("Omega 3", "Anticoagulantes")
```




### **ğŸ“Œ Ajustar AWS Lambda para Mayor Velocidad**
AWS Lambda estÃ¡ optimizado para `aarch64`, pero puedes aumentar memoria si procesas documentos mÃ¡s grandes:

```bash
aws lambda update-function-configuration --function-name MedicalRAG --memory-size 2048
```

ğŸ“Œ **AWS Lambda SnapStart ya estÃ¡ activado automÃ¡ticamente para reducir tiempos de inicio.**  

aws lambda update-function-configuration --function-name MedicalRAG --snapstart-enabled
```

### **ğŸ“Œ Optimizar Consultas en DynamoDB**
DynamoDB ya usa **Auto Scaling**, pero puedes ajustar la capacidad manualmente:

aws dynamodb update-table --table-name MedicalData --provisioned-throughput ReadCapacityUnits=10,WriteCapacityUnits=5
```

ğŸ“Œ **Si tienes cargas variables de datos, Auto Scaling es la mejor opciÃ³n.**  

---

## ğŸ”¹ 5ï¸âƒ£ Seguridad Avanzada y Cifrado de Datos

Medical-RAGArch-System ya implementa **cifrado AES-256 y autenticaciÃ³n con **. Puedes ajustarlos:

### **ğŸ“Œ AES-256 ya estÃ¡ habilitado; puedes personalizar su configuraciÃ³n**
```python
from cryptography.fernet import Fernet

key = Fernet.generate_key()
cipher_suite = Fernet(key)

encrypted_data = cipher_suite.encrypt(b"Texto mÃ©dico confidencial")
```

ğŸ“Œ **Nunca almacenes la clave de cifrado en texto plano.**  

### **ğŸ“Œ Configurar  para ProtecciÃ³n de API**
```python
ACCESS_TOKEN_EXPIRE_MINUTES = 60  # ExpiraciÃ³n de tokens en 1 hora
```

ğŸ“Œ **Todos los accesos requieren autenticaciÃ³n con  para seguridad.**  

---

## ğŸ”¹ 6ï¸âƒ£ Escenarios de PersonalizaciÃ³n

ğŸ“Œ **Escenario 1: Uso estÃ¡ndar con respuestas rÃ¡pidas**  
âœ… **ConfiguraciÃ³n recomendada:**  
- Activar Redis con **cachÃ© de 1 hora** (`CACHE_EXPIRY = 3600`).  
- Usar un modelo NLP ligero (`distilbert-base-uncased`).  
- AWS Lambda con **1024 MB de memoria** para reducir costos.  

ğŸ“Œ **Escenario 2: Procesamiento intensivo de documentos con OCR**  
âœ… **ConfiguraciÃ³n recomendada:**  
- Usar un modelo NLP avanzado (`facebook/bart-large-cnn`).  
- AWS Lambda con **2048 MB de memoria** para mejorar procesamiento.  
- Aplicar **filtros en OpenCV** para mejorar calidad de imÃ¡genes OCR.  

ğŸ“Œ **Escenario 3: Seguridad avanzada y acceso restringido**  
âœ… **ConfiguraciÃ³n recomendada:**  
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

- Cifrar datos mÃ©dicos con **AES-256** antes de almacenarlos.  
- Restringir acceso a la API configurando **CORS restrictivo**.  

---



### ğŸ“Œ Mejoras de OptimizaciÃ³n Aplicadas
Se han implementado optimizaciones adicionales para mejorar el rendimiento sin afectar el uso gratuito:

âœ… **Carga optimizada de dependencias** en mÃ³dulos crÃ­ticos (`dynamodb_optimization.py`, `numba_optimization.py`, `tensorflow_optimization.py`).  
âœ… **DAX en DynamoDB mejorado** con cifrado TLS (`aws/enable_dax.py`).  
âœ… **SnapStart en AWS Lambda** confirmado y optimizado (`aws/lambda_snapstart.py`).  
âœ… **Redis Cache** ahora usa TTL para reducir peticiones innecesarias a DynamoDB (`modules/cache/cache_redis.py`).  

Estas mejoras reducen el consumo de recursos y mejoran los tiempos de respuesta.

## ğŸ“Œ ConclusiÃ³n Final

âœ” **El sistema estÃ¡ optimizado exclusivamente para `aarch64` y no es compatible con Windows.**  
âœ” **Redis, AWS Lambda SnapStart y Auto Scaling en DynamoDB ya estÃ¡n configurados automÃ¡ticamente.**  
âœ” **Las consultas en tiempo real usan WebSockets para minimizar latencias.**  
âœ” **La seguridad incluye autenticaciÃ³n con  y cifrado AES-256.**  
âœ” **Cada parÃ¡metro se puede ajustar para personalizar velocidad, seguridad y costos.**  

ğŸ“Œ **Estas configuraciones avanzadas te permiten personalizar el sistema segÃºn las necesidades del entorno, desde uso ligero hasta procesamiento masivo de datos mÃ©dicos.**  
---

## ğŸ“Œ Diferencia entre CÃ³digo Python y Comandos Bash

Medical-RAGArch-System incluye configuraciones que pueden ajustarse mediante **Python** y **comandos Bash**. Es importante saber **cuÃ¡ndo editar archivos y cuÃ¡ndo ejecutar comandos en la terminal**.

### ğŸ”¹ **CÃ³digo Python en los documentos**
âœ” **Los fragmentos de cÃ³digo Python ya estÃ¡n implementados en el sistema**.  
âœ” **Solo necesitas modificarlos si deseas personalizar la configuraciÃ³n.**  
âœ” **Si un archivo especÃ­fico es mencionado (`api/main.py`, `nlp_config.py`), edÃ­talo ahÃ­.**  

ğŸ“Œ **Ejemplo de ajuste en Python (modificar en `nlp_config.py`)**  
```python
summarizer = pipeline('summarization', max_length=500, min_length=250, do_sample=True)
```

### ğŸ”¹ **Comandos Bash en los documentos**
âœ” **Se ejecutan en la terminal (Linux/macOS o AWS CloudShell).**  
âœ” **NO debes pegarlos dentro del cÃ³digo del proyecto.**  
âœ” **Se usan para configurar AWS Lambda, Redis o DynamoDB manualmente.**  

ğŸ“Œ **Ejemplo de comando Bash (ejecutar en la terminal)**  
aws lambda update-function-configuration --function-name MedicalRAG --memory-size 2048
```

ğŸš€ **Si no estÃ¡s seguro de quÃ© hacer, revisa si el ajuste ya estÃ¡ preconfigurado en el sistema antes de modificarlo.**  


# ğŸ—ï¸ Arquitectura del Sistema - Medical-RAGArch-System

Medical-RAGArch-System utiliza una **arquitectura modular** optimizada para **procesamiento de datos mÃ©dicos**, **integraciÃ³n con IA**, y **almacenamiento en la nube**.

âœ… **ExplicaciÃ³n de cada mÃ³dulo y su funciÃ³n en el sistema.**  
âœ… **Flujo de datos desde la carga de documentos hasta la consulta de ChatGPT.**  
âœ… **Diagrama de arquitectura para visualizar la interacciÃ³n entre componentes.**  
âœ… **Opciones avanzadas de personalizaciÃ³n para mejorar rendimiento.**  

---

## ğŸ”¹ 1ï¸âƒ£ Componentes Principales

Medical-RAGArch-System estÃ¡ compuesto por varios mÃ³dulos que trabajan en conjunto:

| **Componente** | **FunciÃ³n** |
|--------------|------------------|
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

| **NLP (Intelligent Context)** | Procesa consultas, resume textos y extrae palabras clave. |
| **OCR + RAG** | Convierte imÃ¡genes en texto y analiza documentos mÃ©dicos. |
| **DynamoDB** | Base de datos NoSQL utilizada para almacenar los documentos procesados. |
| **Redis Cloud** | CachÃ© en memoria para reducir tiempos de consulta y optimizar respuesta. |
| **AWS Lambda** | Procesa documentos y consultas sin necesidad de servidores persistentes. |
| **GitHub Actions** | Automatiza el despliegue en AWS para mantener el sistema actualizado. |
| **WebSockets** | Permiten consultas en tiempo real sin necesidad de mÃºltiples solicitudes HTTP. |

ğŸ“Œ **Notas**:  
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

- **Redis almacena consultas frecuentes para evitar accesos constantes a DynamoDB.**  
- **AWS Lambda permite ejecutar procesamiento sin depender de servidores dedicados.**  

---

## ğŸ”¹ 2ï¸âƒ£ Flujo de Datos en el Sistema

### **ğŸ“Œ Proceso desde la Carga hasta la Respuesta de ChatGPT**

1ï¸âƒ£ **Carga de documentos** en AWS S3 o vÃ­a API REST.  
2ï¸âƒ£ **OCR + RAG** procesan los documentos y extraen informaciÃ³n clave.  
3ï¸âƒ£ **Los datos se almacenan en DynamoDB** para consultas posteriores.  
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

5ï¸âƒ£ **El mÃ³dulo NLP procesa la consulta, resume texto y extrae palabras clave.**  
6ï¸âƒ£ **Si la consulta ya ha sido realizada, Redis devuelve la respuesta desde cachÃ©.**  
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.


ğŸ“Œ **Ejemplo de una Consulta en Tiempo Real:**  
Si ChatGPT pregunta: `"Â¿CuÃ¡les son los sÃ­ntomas principales del documento ID 12345?"`  
El sistema:
- Extrae los sÃ­ntomas clave usando NLP.  
- Revisa en Redis si la respuesta ya ha sido calculada.  
- Si no estÃ¡ en cachÃ©, consulta DynamoDB y procesa los datos en AWS Lambda.  
- Devuelve la respuesta a ChatGPT en segundos.  

ğŸ“Œ **Diagrama del Flujo de Datos:**  
```
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

                           |                 |
                          [Redis]       [AWS Lambda]
                             |                 |
                        [Respuesta a ChatGPT] <---
```

---

## ğŸ”¹ 3ï¸âƒ£ ConfiguraciÃ³n y PersonalizaciÃ³n de Componentes

Cada mÃ³dulo del sistema puede ajustarse para optimizar rendimiento y funcionalidad:

âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

Si necesitas modificar el puerto o activar WebSockets, edita `api/main.py`:

```python
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"])
```

ğŸ“Œ **Consejo:** **Limita los orÃ­genes permitidos en producciÃ³n** para evitar accesos no autorizados.

---

### **ğŸ“Œ Ajuste de NLP para Mejor Resumen de Textos**
Si deseas que el sistema genere respuestas mÃ¡s concisas o mÃ¡s detalladas:

```python
summarizer = pipeline('summarization', model="facebook/bart-large-cnn", max_length=250, min_length=100, do_sample=True)
```

ğŸ“Œ **Opciones avanzadas:**  
- **Mayor detalle** â†’ Aumenta `max_length` a 500.  
- **Respuestas mÃ¡s breves** â†’ Reduce `min_length` a 50.  

---

### **ğŸ“Œ ConfiguraciÃ³n de Redis para Optimizar CachÃ©**
Si deseas cambiar el tiempo de almacenamiento en cachÃ©:

```python
CACHE_EXPIRY = 1800  # ExpiraciÃ³n en 30 minutos
```

ğŸ“Œ **Consejo:** Reduce el tiempo de expiraciÃ³n si los datos cambian con frecuencia.

---

### **ğŸ“Œ Ajuste de AWS Lambda para Mayor Rendimiento**
Si necesitas mÃ¡s memoria en AWS Lambda para procesar documentos grandes:

aws lambda update-function-configuration --function-name MedicalRAG --memory-size 2048
```

ğŸ“Œ **Consejo:** Mayor memoria = ejecuciÃ³n mÃ¡s rÃ¡pida, pero puede aumentar costos.

---

## ğŸ”¹ 4ï¸âƒ£ Escenarios de Uso

ğŸ“Œ **Escenario 1: Uso estÃ¡ndar con respuestas rÃ¡pidas**  
âœ… **ConfiguraciÃ³n recomendada:**  
- Activar Redis con un cachÃ© de **1 hora** (`CACHE_EXPIRY = 3600`).  
- Usar un modelo NLP liviano (`distilbert-base-uncased`).  
- AWS Lambda con **1024 MB de memoria** para reducir costos.  

ğŸ“Œ **Escenario 2: Procesamiento de documentos grandes**  
âœ… **ConfiguraciÃ³n recomendada:**  
- Usar un modelo NLP detallado (`facebook/bart-large-cnn`).  
- AWS Lambda con **2048 MB de memoria** para documentos extensos.  
- CachÃ© en Redis reducido a **30 minutos** para datos mÃ¡s dinÃ¡micos.  

ğŸ“Œ **Escenario 3: Consultas en tiempo real con ChatGPT**  
âœ… **ConfiguraciÃ³n recomendada:**  
- Habilitar **WebSockets** (`uvicorn --ws`).  
- Reducir la latencia ajustando `WEBSOCKET_TIMEOUT = 20`.  
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.


---

## ğŸ“Œ ConclusiÃ³n

Medical-RAGArch-System estÃ¡ diseÃ±ado con una arquitectura **modular, escalable y optimizada** para diferentes escenarios:

âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

âœ” **Redis optimiza la respuesta del sistema, reduciendo latencia en consultas frecuentes.**  
âœ” **AWS Lambda permite ejecutar procesos sin servidores dedicados, reduciendo costos.**  
âœ” **La arquitectura puede ajustarse segÃºn las necesidades del usuario, desde procesamiento ligero hasta uso intensivo con modelos avanzados.**  

ğŸ“Œ **Con una configuraciÃ³n adecuada, puedes lograr un balance entre costo, velocidad y precisiÃ³n para adaptarlo a cualquier entorno.**  

---

## ğŸ”¹ 5ï¸âƒ£ Compatibilidad con Hardware y Software

Medical-RAGArch-System ha sido optimizado especÃ­ficamente para **arquitecturas aarch64** y entornos basados en AWS.

### **ğŸ“Œ Arquitectura y CompilaciÃ³n**
âœ… **Compilado y optimizado para:** `aarch64`
âœ… **Eliminado soporte para:** `x86_64` (no compatible con la versiÃ³n actual)  
âœ… **Eliminado soporte para:** `x86_64`  
âœ… **OptimizaciÃ³n de librerÃ­as para menor consumo de recursos en ARM**  

### **ğŸ“Œ Sistemas Operativos Compatibles**
âœ… **Distribuciones Linux (Ubuntu, Debian, Amazon Linux 2, Alpine)**  
âœ… **Contenedores Docker en AWS Lambda y Graviton**  
âœ… **Raspberry Pi 4 y Jetson Nano (para inferencia local en ARM64)**  

ğŸ“Œ **Nota:**  
- **El sistema NO es compatible con Windows**, ya que ha sido diseÃ±ado para ejecutarse en entornos basados en Linux.  
- **Si se necesita soporte en `x86_64`, habrÃ­a que recompilar algunas dependencias con flags especÃ­ficos para esa arquitectura.**  

### **ğŸ“Œ Entornos de EjecuciÃ³n en la Nube**
Medical-RAGArch-System estÃ¡ optimizado para los siguientes entornos en la nube:

| **Proveedor** | **Recomendado** | **Motivo** |
|--------------|-------------|-------------|
| **AWS Lambda (aarch64)** | âœ… SÃ­ | OptimizaciÃ³n con SnapStart y menor costo en Graviton. |
| **Google Cloud Run** | âš ï¸ Parcial | Puede ejecutarse, pero sin soporte directo para aarch64. |
| **Azure Functions** | âŒ No | No tiene soporte nativo para ARM64 en ambientes serverless. |
| **Docker (ARM64)** | âœ… SÃ­ | Puede ejecutarse en contenedores Docker sobre Linux ARM. |

ğŸ“Œ **AWS Lambda con `Graviton` ofrece el mejor rendimiento y menor costo de ejecuciÃ³n.**  

---



### ğŸ“Œ Mejoras de OptimizaciÃ³n Aplicadas
Se han implementado optimizaciones adicionales para mejorar el rendimiento sin afectar el uso gratuito:

âœ… **Carga optimizada de dependencias** en mÃ³dulos crÃ­ticos (`dynamodb_optimization.py`, `numba_optimization.py`, `tensorflow_optimization.py`).  
âœ… **DAX en DynamoDB mejorado** con cifrado TLS (`aws/enable_dax.py`).  
âœ… **SnapStart en AWS Lambda** confirmado y optimizado (`aws/lambda_snapstart.py`).  
âœ… **Redis Cache** ahora usa TTL para reducir peticiones innecesarias a DynamoDB (`modules/cache/cache_redis.py`).  

Estas mejoras reducen el consumo de recursos y mejoran los tiempos de respuesta.

## ğŸ“Œ ConclusiÃ³n Final

âœ” **Medical-RAGArch-System estÃ¡ optimizado para `aarch64` y ejecutÃ¡ndose en AWS Lambda con Graviton.**  
âœ” **No estÃ¡ pensado para Windows ni `x86_64`, lo que permite una mejor eficiencia en entornos cloud.**  
âœ” **Las mejores opciones de despliegue son AWS Lambda, Docker ARM64 y Raspberry Pi 4 para inferencia local.**  
âœ” **Si se requiere compatibilidad con `x86_64`, hay que recompilar algunas dependencias especÃ­ficas.**  

---


Medical-RAGArch-System incluye configuraciones que pueden ajustarse mediante **Python** y **comandos Bash**. Es importante saber **cuÃ¡ndo editar archivos y cuÃ¡ndo ejecutar comandos en la terminal**.

âœ” **Los fragmentos de cÃ³digo Python ya estÃ¡n implementados en el sistema**.  
âœ” **Solo necesitas modificarlos si deseas personalizar la configuraciÃ³n.**  
âœ” **Si un archivo especÃ­fico es mencionado (`api/main.py`, `nlp_config.py`), edÃ­talo ahÃ­.**  

ğŸ“Œ **Ejemplo de ajuste en Python (modificar en `nlp_config.py`)**  
```python
```

âœ” **Se ejecutan en la terminal (Linux/macOS o AWS CloudShell).**  
âœ” **NO debes pegarlos dentro del cÃ³digo del proyecto.**  
âœ” **Se usan para configurar AWS Lambda, Redis o DynamoDB manualmente.**  

ğŸ“Œ **Ejemplo de comando Bash (ejecutar en la terminal)**  
aws lambda update-function-configuration --function-name MedicalRAG --memory-size 2048
```

ğŸš€ **Si no estÃ¡s seguro de quÃ© hacer, revisa si el ajuste ya estÃ¡ preconfigurado en el sistema antes de modificarlo.**  



# ğŸ“Œ Tabla de Contenidos

- [ğŸ“– IntroducciÃ³n](#introducciÃ³n)
- [âš™ï¸ ConfiguraciÃ³n y PersonalizaciÃ³n](#configuraciÃ³n-y-personalizaciÃ³n)
- [ğŸ”„ AutomatizaciÃ³n y Despliegue](#automatizaciÃ³n-y-despliegue)
- [ğŸ“„ Ejemplos de Uso](#ejemplos-de-uso)
  - [ğŸ“‚ Subida y Procesamiento de Documentos](#ejemplos-de-uso---subida-y-procesamiento-de-documentos)
  - [ğŸ§  Procesamiento de Texto y NLP](#ejemplos-de-uso---procesamiento-de-texto-y-nlp)
  - [ğŸ”„ OptimizaciÃ³n y CachÃ©](#ejemplos-de-uso---optimizaciÃ³n-y-cachÃ©)
  - [âš¡ WebSockets y Consultas en Tiempo Real](#ejemplos-de-uso---websockets-y-consultas-en-tiempo-real)
- [ğŸ” OptimizaciÃ³n y Seguridad](#optimizaciÃ³n-y-seguridad)
- [ğŸ“Œ ConclusiÃ³n](#conclusiÃ³n)

---


# ğŸ”„ AutomatizaciÃ³n y ConfiguraciÃ³n en Medical-RAGArch-System

Medical-RAGArch-System estÃ¡ diseÃ±ado para minimizar la intervenciÃ³n del usuario, pero ciertos ajustes pueden requerir configuraciÃ³n manual para optimizar su funcionamiento.

âœ… **QuÃ© procesos estÃ¡n completamente automatizados.**  
âœ… **QuÃ© procesos requieren ajustes manuales y por quÃ©.**  
âœ… **CÃ³mo personalizar la configuraciÃ³n para mejorar rendimiento y eficiencia.**  
âœ… **Casos de uso para diferentes niveles de automatizaciÃ³n.**  

---

## ğŸ”¹ 1ï¸âƒ£ Procesos Totalmente Automatizados


# ğŸš€ IntegraciÃ³n con AWS (Lambda, DynamoDB, API Gateway)

Este proyecto utiliza mÃºltiples servicios de **AWS** para mejorar su rendimiento, escalabilidad y disponibilidad.

## ğŸ“Œ **Servicios Utilizados**

| Servicio      | FunciÃ³n en el Proyecto |
|--------------|------------------------|
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

| **DynamoDB** | Base de datos NoSQL optimizada para respuestas rÃ¡pidas |
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

| **SnapStart** | Reduce los tiempos de arranque de Lambda |
| **DAX** | Acelera las consultas en DynamoDB |

## âš™ï¸ **ConfiguraciÃ³n Manual en AWS**
Si deseas configurar manualmente los servicios en AWS, sigue estos pasos:

### **1ï¸âƒ£ Configurar AWS Lambda**
```bash
aws lambda create-function --function-name MedicalRAG --runtime python3.8 --role <IAM_ROLE> --handler api.main.lambda_handler
```

### **2ï¸âƒ£ Configurar DynamoDB**
```bash
aws dynamodb create-table --table-name MedicalData --attribute-definitions AttributeName=id,AttributeType=S --key-schema AttributeName=id,KeyType=HASH --billing-mode PAY_PER_REQUEST
```

---

## ğŸ› ï¸ **ConfiguraciÃ³n AutomÃ¡tica con CDK**
Si prefieres desplegarlo automÃ¡ticamente, usa los scripts de `aws/`:
```bash
cd aws/
python enable_dax.py  # Activa DAX en DynamoDB
python lambda_snapstart.py  # Habilita SnapStart en AWS Lambda
```




Estos procesos se ejecutan sin intervenciÃ³n manual una vez configurados:

| **Funcionalidad** | **AutomatizaciÃ³n** | **ExplicaciÃ³n** |
|--------------|-------------|-------------|
| **Carga y procesamiento de documentos** | âœ… SÃ­ | El sistema detecta automÃ¡ticamente el tipo de documento y lo procesa. |
| **OCR automÃ¡tico** | âœ… SÃ­ | Si el documento es una imagen escaneada, el OCR se activa sin necesidad de ajuste manual. |
| **OptimizaciÃ³n de consultas con Redis** | âœ… SÃ­ | Las consultas repetidas se almacenan en cachÃ© para reducir la carga en DynamoDB. |
| **Despliegue en AWS Lambda y DynamoDB con GitHub Actions** | âœ… SÃ­ | El cÃ³digo se actualiza y despliega automÃ¡ticamente sin intervenciÃ³n. |
| **Auto Scaling en DynamoDB** | âœ… SÃ­ | Se ajusta la capacidad de la base de datos segÃºn la demanda del sistema. |
| **GeneraciÃ³n de respuestas estructuradas para ChatGPT** | âœ… SÃ­ | Las respuestas son resumidas y formateadas automÃ¡ticamente antes de enviarlas. |

ğŸ“Œ **Notas**:  
- **Si subes un documento PDF, el sistema determina automÃ¡ticamente si necesita OCR.**  
- **El almacenamiento en Redis estÃ¡ preconfigurado y optimizado.**  
- **AWS Lambda ajusta automÃ¡ticamente los recursos segÃºn la carga.**  

---

## ğŸ”¹ 2ï¸âƒ£ Procesos que Requieren ConfiguraciÃ³n Manual


# ğŸš€ OptimizaciÃ³n con Redis y Numba

Este proyecto utiliza **Redis Cloud** y **Numba** para mejorar el rendimiento en tiempo de respuesta y cÃ¡lculos intensivos.

## ğŸ“Œ **OptimizaciÃ³n con Redis**

Redis se usa para **cachear respuestas frecuentes**, reduciendo la carga en DynamoDB.

### **ğŸ“Œ ConfiguraciÃ³n Manual de Redis**
1ï¸âƒ£ Crea un clÃºster de Redis en AWS o usa una instancia local.  
2ï¸âƒ£ Configura el archivo `config/redis_config.py` con las credenciales:

```python
REDIS_HOST = "redis-cluster.amazonaws.com"
REDIS_PORT = 6379
REDIS_REMOVED_SECRET
```

### **ğŸ“Œ Uso en el CÃ³digo**
```python
import redis

cache = redis.StrictRedis(host=REDIS_HOST, port=REDIS_PORT, password=REDIS_PASSWORD, decode_responses=True)
cache.set("consulta_usuario", resultado_procesado, ex=3600)  # Cache por 1 hora
```

---

## âš¡ **OptimizaciÃ³n con Numba**
Numba acelera cÃ¡lculos de Machine Learning y NLP optimizando operaciones matemÃ¡ticas intensivas.

### **ğŸ“Œ Ejemplo de Uso**
```python
from numba import jit

@jit(nopython=True)
def calcular_metricas(datos):
    return sum(datos) / len(datos)
```




Algunas funciones necesitan intervenciÃ³n manual para ajustarse a escenarios especÃ­ficos:

| **Funcionalidad** | **IntervenciÃ³n Manual** | **Motivo** |
|--------------|-------------|-------------|
| **Ajuste de umbral en OCR** | âš ï¸ SÃ­ | Dependiendo de la calidad de la imagen, puede ser necesario ajustar la precisiÃ³n del OCR. |
| **PolÃ­ticas de retenciÃ³n de datos en DynamoDB** | âš ï¸ SÃ­ | Por defecto, los datos se almacenan indefinidamente, pero pueden configurarse reglas de expiraciÃ³n. |
| **ModificaciÃ³n del NLP para respuestas mÃ¡s detalladas o resumidas** | âš ï¸ SÃ­ | Se puede modificar el nivel de resumen en el modelo de NLP. |
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

| **Seguridad y autenticaciÃ³n avanzada** | âš ï¸ SÃ­ | Si se necesita una capa extra de seguridad, se pueden modificar los mÃ©todos de autenticaciÃ³n. |

ğŸ“Œ **Ejemplo de ajuste en OCR:**  
Si un documento escaneado tiene mala calidad, se puede mejorar la detecciÃ³n ajustando `ocr_advanced.py`:

```python
ocr_engine.set_threshold(0.90)  # Mayor precisiÃ³n, pero puede omitir texto con bajo contraste
```

ğŸ“Œ **Ejemplo de ajuste en DynamoDB:**  
Si no quieres almacenar documentos indefinidamente, puedes configurar una polÃ­tica de expiraciÃ³n:

aws dynamodb update-time-to-live --table-name MedicalData --time-to-live-specification Enabled=true,AttributeName=expiration_timestamp
```

ğŸ“Œ **Ejemplo de ajuste en NLP para ChatGPT:**  
Si deseas respuestas mÃ¡s extensas y detalladas en consultas:

```python
summarizer = pipeline('summarization', max_length=800, min_length=300, do_sample=True)
```

---

## ğŸ”¹ 3ï¸âƒ£ Casos PrÃ¡cticos para Diferentes Niveles de AutomatizaciÃ³n


# ğŸ¤– Modelos de Machine Learning y NLP

El sistema incluye modelos de **predicciÃ³n y procesamiento de lenguaje natural (NLP)** para analizar documentos mÃ©dicos.

## ğŸ“Œ **Modelos Implementados**
| MÃ³dulo | Funcionalidad |
|--------|--------------|
| **ml_models.py** | Modelos de predicciÃ³n y clasificaciÃ³n |
| **intelligent_context.py** | Procesamiento avanzado de lenguaje natural |
| **time_series.py** | Predicciones basadas en series temporales |

---

## âš™ï¸ **CÃ³mo Personalizar los Modelos**

### **Modificar ParÃ¡metros del Modelo NLP**
Edita el archivo `config/nlp_config.json`:
```json
{
    "max_length": 500,
    "min_length": 200,
    "do_sample": true
}
```

### **Ejemplo de Uso en el CÃ³digo**
```python
from transformers import pipeline

summarizer = pipeline("summarization", max_length=500, min_length=200, do_sample=True)
```




### **Escenario 1: Uso estÃ¡ndar con automatizaciÃ³n total**  
ğŸ”¹ **Tienes documentos en AWS S3 y deseas analizarlos automÃ¡ticamente.**  
âœ… **SoluciÃ³n:** Configura una regla en AWS Lambda para que procese cualquier archivo nuevo automÃ¡ticamente.  

```json
{
  "source": "AWS-S3",
  "processing_mode": "AUTO"
}
```

ğŸ”¹ **El sistema identificarÃ¡ el documento, aplicarÃ¡ OCR si es necesario y almacenarÃ¡ los datos en DynamoDB sin intervenciÃ³n manual.**  

---

### **Escenario 2: Seguridad Avanzada y RetenciÃ³n de Datos**  
ğŸ”¹ **Requieres mayor control sobre los tiempos de expiraciÃ³n de los documentos.**  
âœ… **SoluciÃ³n:** Configura polÃ­ticas de retenciÃ³n en DynamoDB y habilita autenticaciÃ³n avanzada con .  

export TOKEN_EXPIRATION=3600  # ExpiraciÃ³n de tokens en 1 hora
```

ğŸ”¹ **Esto permitirÃ¡ que solo usuarios autorizados puedan acceder a los documentos almacenados.**  

---

### **Escenario 3: Activar WebSockets para Consultas en Tiempo Real**  
ğŸ”¹ **Quieres que ChatGPT pueda obtener respuestas sin esperar consultas HTTP tradicionales.**  
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.


uvicorn api.main:app --host 0.0.0.0 --port 8000 --ws
```

ğŸ”¹ **Esto permitirÃ¡ que las respuestas lleguen en tiempo real sin latencia adicional.**  

---

## ğŸ“Œ ConclusiÃ³n

Medical-RAGArch-System es altamente automatizable, pero ciertos procesos pueden ajustarse para mejorar la precisiÃ³n y la seguridad:

âœ… **Si necesitas un sistema completamente autÃ³nomo**, las funciones predeterminadas de automatizaciÃ³n ya manejan la mayorÃ­a de los procesos.  
âœ… **Si deseas control sobre la seguridad, tiempos de respuesta y ajustes avanzados, puedes configurar manualmente los mÃ³dulos segÃºn las necesidades especÃ­ficas.**  
âœ… **Con la combinaciÃ³n correcta de automatizaciÃ³n y ajustes manuales, puedes personalizar el sistema para adaptarse a cualquier entorno de trabajo.**  
---


Medical-RAGArch-System incluye configuraciones que pueden ajustarse mediante **Python** y **comandos Bash**. Es importante saber **cuÃ¡ndo editar archivos y cuÃ¡ndo ejecutar comandos en la terminal**.

âœ” **Los fragmentos de cÃ³digo Python ya estÃ¡n implementados en el sistema**.  
âœ” **Solo necesitas modificarlos si deseas personalizar la configuraciÃ³n.**  
âœ” **Si un archivo especÃ­fico es mencionado (`api/main.py`, `nlp_config.py`), edÃ­talo ahÃ­.**  

ğŸ“Œ **Ejemplo de ajuste en Python (modificar en `nlp_config.py`)**  
```python
```

âœ” **Se ejecutan en la terminal (Linux/macOS o AWS CloudShell).**  
âœ” **NO debes pegarlos dentro del cÃ³digo del proyecto.**  
âœ” **Se usan para configurar AWS Lambda, Redis o DynamoDB manualmente.**  

ğŸ“Œ **Ejemplo de comando Bash (ejecutar en la terminal)**  
aws lambda update-function-configuration --function-name MedicalRAG --memory-size 2048
```

ğŸš€ **Si no estÃ¡s seguro de quÃ© hacer, revisa si el ajuste ya estÃ¡ preconfigurado en el sistema antes de modificarlo.**  


# ğŸ“Œ Ejemplos Avanzados en Medical-RAGArch-System

Este archivo detalla **casos de uso avanzados** con ejemplos prÃ¡cticos sobre **integraciÃ³n con AWS, WebSockets, OCR avanzado, NLP y optimizaciÃ³n de respuestas.**

---

## ğŸ”¹ 1ï¸âƒ£ Subida Avanzada de Documentos con AWS S3

Si los documentos ya estÃ¡n almacenados en AWS S3, puedes referenciarlos en lugar de subirlos manualmente.

### **ğŸ“Œ PeticiÃ³n API para registrar un documento de S3**
```json
{
  "document_url": "s3://medical-docs/documento.pdf"
}
```

ğŸ“Œ **ExplicaciÃ³n:**  
- El sistema recuperarÃ¡ el documento directamente desde **AWS S3**.  
- Se aplicarÃ¡ OCR automÃ¡ticamente si es necesario.  
- Se generarÃ¡ un `document_id` para futuras consultas.  

---

## ğŸ”¹ 2ï¸âƒ£ PersonalizaciÃ³n de Respuestas en NLP

Si deseas personalizar cÃ³mo el sistema resume documentos, puedes ajustar los parÃ¡metros en `intelligent_context.py`.

### **ğŸ“Œ Ajuste del modelo de NLP**
```python
summarizer = pipeline('summarization', model="facebook/bart-large-cnn", max_length=500, min_length=200, do_sample=True)
```

ğŸ“Œ **Opciones recomendadas:**  
âœ… **Para respuestas mÃ¡s detalladas:** `max_length=800, min_length=300`  
âœ… **Para respuestas mÃ¡s rÃ¡pidas:** `max_length=250, min_length=100`  

---

## ğŸ”¹ 3ï¸âƒ£ ConfiguraciÃ³n de OCR con Preprocesamiento de ImÃ¡genes

Si un documento escaneado tiene baja calidad, puedes mejorar la precisiÃ³n del OCR antes del procesamiento.

### **ğŸ“Œ Aplicar preprocesamiento con OpenCV**
```python
import cv2

image = cv2.imread("documento.jpg")
image = cv2.convertScaleAbs(image, alpha=1.5, beta=30)  # Ajusta brillo y contraste
cv2.imwrite("documento_mejorado.jpg", image)
```

ğŸ“Œ **ExplicaciÃ³n:**  
- **Si el texto es muy claro**, reduce `alpha` para disminuir brillo.  
- **Si la imagen tiene ruido**, usa `cv2.GaussianBlur(image, (5, 5), 0)`.  

---

## ğŸ”¹ 4ï¸âƒ£ OptimizaciÃ³n con Redis y DynamoDB

Redis ya estÃ¡ habilitado en el sistema. Puedes ajustar su tiempo de expiraciÃ³n para mejorar la eficiencia.

### **ğŸ“Œ ConfiguraciÃ³n de Redis**
```python
CACHE_EXPIRY = 3600  # Respuestas almacenadas durante 1 hora
```

ğŸ“Œ **ExplicaciÃ³n:**  
âœ… **Si los datos cambian con frecuencia**, reduce `CACHE_EXPIRY` a `600` segundos.  
âœ… **Si consultas documentos estÃ¡ticos**, aumenta el cachÃ© a `86400` segundos (1 dÃ­a).  

---

## ğŸ”¹ 5ï¸âƒ£ WebSockets para Consultas en Tiempo Real

Para obtener respuestas inmediatas sin esperar una consulta HTTP, habilita WebSockets.

### **ğŸ“Œ Conectar WebSockets desde Python**
```python
import websockets
import asyncio

async def test_websocket():
    async with websockets.connect("ws://localhost:8000/ws") as websocket:
        await websocket.send("Resumen del documento 12345")
        response = await websocket.recv()
        print(response)

asyncio.run(test_websocket())
```

ğŸ“Œ **Beneficios:**  
âœ… Respuestas en tiempo real sin mÃºltiples peticiones HTTP.  
âœ… ReducciÃ³n de latencia en consultas de ChatGPT.  

---

## ğŸ“Œ ConclusiÃ³n

Estos ejemplos avanzados permiten maximizar el rendimiento del sistema con:  
âœ” **Carga de documentos desde AWS S3.**  
âœ” **Preprocesamiento de imÃ¡genes para OCR mÃ¡s preciso.**  
âœ” **OptimizaciÃ³n de Redis y DynamoDB para respuestas mÃ¡s rÃ¡pidas.**  
âœ” **Uso de WebSockets para comunicaciÃ³n en tiempo real.**  
âœ” **PersonalizaciÃ³n del procesamiento NLP para mejorar respuestas.**  

---


Medical-RAGArch-System incluye configuraciones que pueden ajustarse mediante **Python** y **comandos Bash**. Es importante saber **cuÃ¡ndo editar archivos y cuÃ¡ndo ejecutar comandos en la terminal**.

âœ” **Los fragmentos de cÃ³digo Python ya estÃ¡n implementados en el sistema**.  
âœ” **Solo necesitas modificarlos si deseas personalizar la configuraciÃ³n.**  
âœ” **Si un archivo especÃ­fico es mencionado (`api/main.py`, `nlp_config.py`), edÃ­talo ahÃ­.**  

ğŸ“Œ **Ejemplo de ajuste en Python (modificar en `nlp_config.py`)**  
```python
```

âœ” **Se ejecutan en la terminal (Linux/macOS o AWS CloudShell).**  
âœ” **NO debes pegarlos dentro del cÃ³digo del proyecto.**  
âœ” **Se usan para configurar AWS Lambda, Redis o DynamoDB manualmente.**  

ğŸ“Œ **Ejemplo de comando Bash (ejecutar en la terminal)**  
aws lambda update-function-configuration --function-name MedicalRAG --memory-size 2048
```

ğŸš€ **Si no estÃ¡s seguro de quÃ© hacer, revisa si el ajuste ya estÃ¡ preconfigurado en el sistema antes de modificarlo.**  


# ğŸ“Œ Ejemplos de Uso en Medical-RAGArch-System

âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.


---

## ğŸ”¹ 1ï¸âƒ£ Subir un Documento y Procesarlo

âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.


### **ğŸ“Œ Comando en Terminal (Linux/Mac)**
curl -X POST "https://tu-endpoint.com/upload" -H "Authorization: Bearer TU_TOKEN" -F "file=@documento.pdf"
```

### **ğŸ“Œ Respuesta esperada**
```json
{
  "message": "Documento recibido y procesado correctamente.",
  "document_id": "12345"
}
```

ğŸ“Œ **Nota:** Puedes subir archivos en formatos `.pdf`, `.jpg`, `.png`, `.txt`, y `.json`. Si el sistema detecta un documento escaneado, aplicarÃ¡ OCR automÃ¡ticamente.

---

## ğŸ”¹ 2ï¸âƒ£ Consultar InformaciÃ³n desde ChatGPT con Herramientas

Si ChatGPT necesita obtener un resumen de un documento, puede realizar la siguiente consulta:

### **ğŸ“Œ PeticiÃ³n desde ChatGPT**
```json
{
  "query": "Dame un resumen del documento con ID 12345",
  "source": "Medical-RAGArch-System"
}
```

### **ğŸ“Œ Respuesta esperada**
```json
{
  "response": "El documento 12345 trata sobre diabetes tipo 2 y su manejo con metformina."
}
```

ğŸ“Œ **Nota:** Si el documento aÃºn no ha sido procesado, la respuesta indicarÃ¡ que no se encontraron datos.

---

## ğŸ”¹ 3ï¸âƒ£ Configurar OCR para Mayor PrecisiÃ³n

Si el OCR tiene dificultades para reconocer texto en imÃ¡genes de baja calidad, puedes aumentar la sensibilidad en `ocr_advanced.py`.

### **ğŸ“Œ Ajustar umbral de OCR en `ocr_advanced.py`**
```python
ocr_engine.set_threshold(0.85)  # Ajustar entre 0.5 y 0.95 segÃºn la calidad de las imÃ¡genes
```

ğŸ“Œ **Recomendaciones:**  
âœ… **Si el texto es borroso**, usa un umbral mÃ¡s alto (`0.90+`).  
âœ… **Si OCR detecta texto errÃ³neo**, reduce el umbral (`0.75-`).  

---

## ğŸ”¹ 4ï¸âƒ£ ComunicaciÃ³n en Tiempo Real con WebSockets

âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.


âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

uvicorn app:app --host 0.0.0.0 --port 8000
```

2ï¸âƒ£ **ConÃ©ctate al WebSocket con Python**
```python
import websockets
import asyncio

async def test_websocket():
    async with websockets.connect("ws://localhost:8000/ws") as websocket:
        await websocket.send("Dame un resumen del documento 12345")
        response = await websocket.recv()
        print(response)

asyncio.run(test_websocket())
```

ğŸ“Œ **Ventajas del WebSocket:**  
âœ… Responde en tiempo real sin necesidad de nuevas peticiones HTTP.  
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.


---

## ğŸ”¹ 5ï¸âƒ£ OptimizaciÃ³n de Procesamiento de Texto en NLP

Si quieres personalizar cÃ³mo el sistema procesa los textos, puedes modificar la configuraciÃ³n de `intelligent_context.py`.

### **ğŸ“Œ Ajustar la longitud del resumen NLP**
```python
summarizer = pipeline('summarization', max_length=250, min_length=100, do_sample=True)
```

ğŸ“Œ **Opciones:**  
âœ… Si quieres **resÃºmenes mÃ¡s breves**, reduce `max_length` a 150.  
âœ… Si necesitas mÃ¡s contexto, aumenta `max_length` a 500.  

---

## ğŸ”¹ 6ï¸âƒ£ Uso de Redis para OptimizaciÃ³n de Consultas

Redis ya estÃ¡ habilitado en el sistema. Puedes optimizar su configuraciÃ³n para mejorar la eficiencia en consultas repetitivas.

### **ğŸ“Œ Configurar almacenamiento en cachÃ© en `redis_cloud.py`**
```python
import redis

cache = redis.StrictRedis(host="redis-instance-url", port=6379, db=0)

def get_cached_response(query):
    response = cache.get(query)
    if response:
        return response.decode("utf-8")
    return None
```

ğŸ“Œ **Beneficios de usar Redis:**  
âœ… Reduce la carga en DynamoDB al evitar consultas repetidas.  
âœ… Mejora la velocidad de respuesta para ChatGPT.  

---

## ğŸ”¹ 7ï¸âƒ£ AWS Lambda SnapStart para Mejora de Velocidad

Si el sistema se ejecuta en AWS Lambda, puedes habilitar SnapStart para reducir tiempos de inicio.

aws lambda update-function-configuration --function-name MedicalRAG --snapstart-enabled
```

ğŸ“Œ **Beneficios:**  
âœ… Acelera la ejecuciÃ³n de Lambda hasta un **60% mÃ¡s rÃ¡pido**.  
âœ… Reduce los costos al evitar largos tiempos de espera.  

---

## ğŸ“Œ ConclusiÃ³n

Estos ejemplos cubren los usos mÃ¡s comunes dentro del sistema. Dependiendo de la carga de trabajo, puedes:
- **Optimizar el OCR** si procesas imÃ¡genes escaneadas.  
- **Usar WebSockets** para comunicaciÃ³n en tiempo real.  
- **Optimizar Redis** si se realizan muchas consultas repetitivas.  
- **Habilitar AWS SnapStart** para mejorar la velocidad de respuesta.  
---


Medical-RAGArch-System incluye configuraciones que pueden ajustarse mediante **Python** y **comandos Bash**. Es importante saber **cuÃ¡ndo editar archivos y cuÃ¡ndo ejecutar comandos en la terminal**.

âœ” **Los fragmentos de cÃ³digo Python ya estÃ¡n implementados en el sistema**.  
âœ” **Solo necesitas modificarlos si deseas personalizar la configuraciÃ³n.**  
âœ” **Si un archivo especÃ­fico es mencionado (`api/main.py`, `nlp_config.py`), edÃ­talo ahÃ­.**  

ğŸ“Œ **Ejemplo de ajuste en Python (modificar en `nlp_config.py`)**  
```python
```

âœ” **Se ejecutan en la terminal (Linux/macOS o AWS CloudShell).**  
âœ” **NO debes pegarlos dentro del cÃ³digo del proyecto.**  
âœ” **Se usan para configurar AWS Lambda, Redis o DynamoDB manualmente.**  

ğŸ“Œ **Ejemplo de comando Bash (ejecutar en la terminal)**  
aws lambda update-function-configuration --function-name MedicalRAG --memory-size 2048
```

ğŸš€ **Si no estÃ¡s seguro de quÃ© hacer, revisa si el ajuste ya estÃ¡ preconfigurado en el sistema antes de modificarlo.**  


### ğŸ”¹ **InteracciÃ³n con CÃ³digo Python y Comandos Bash**

Medical-RAGArch-System permite ajustar configuraciones y ejecutar acciones a travÃ©s de cÃ³digo Python y comandos Bash.
Esta secciÃ³n explica cuÃ¡ndo usar cada uno y proporciona ejemplos claros.

---

### ğŸ”¹ **Uso de CÃ³digo Python**

âœ” **Los fragmentos de cÃ³digo Python ya estÃ¡n implementados en el sistema.**
âœ” **Solo necesitas modificarlos si deseas personalizar la configuraciÃ³n.**
âœ” **Si un archivo especÃ­fico es mencionado (`api/main.py`, `nlp_config.py`), edÃ­talo ahÃ­.**

ğŸ“Œ **Ejemplo de ajuste en Python (modificar en `nlp_config.py`)**
```python
summarizer = pipeline('summarization', max_length=500, min_length=250, do_sample=True)
```

ğŸ“Œ **Otros ejemplos de cÃ³digo en Python utilizados en diferentes secciones:**

- **WebSockets:** ComunicaciÃ³n en tiempo real con consultas optimizadas.
- **OCR con OpenCV:** Mejora de precisiÃ³n en documentos escaneados.
- **OptimizaciÃ³n de cachÃ© con Redis:** Acelerar consultas frecuentes.

---

### ğŸ”¹ **Uso de Comandos Bash**

âœ” **Se ejecutan en la terminal (Linux/macOS o AWS CloudShell).**
âœ” **NO debes pegarlos dentro del cÃ³digo del proyecto.**
âœ” **Se usan para configurar AWS Lambda, Redis o DynamoDB manualmente.**

ğŸ“Œ **Ejemplo de comando Bash (ejecutar en la terminal)**
aws lambda update-function-configuration --function-name MedicalRAG --memory-size 2048
```

ğŸ“Œ **Otros comandos Ãºtiles:**

- **Configurar OCR avanzado en AWS Lambda**
- **Habilitar SnapStart para mejorar tiempos de ejecuciÃ³n**
- **Ajustar escalado automÃ¡tico en DynamoDB**

---

















---

# Medical-RAGArch-System

## ğŸ“Œ Â¿QuÃ© es este proyecto?
Medical-RAGArch-System es un sistema de **IA aplicada a documentos mÃ©dicos**, que permite:
- **Almacenar, procesar y recuperar informaciÃ³n estructurada** de documentos mÃ©dicos.
- **Optimizar la infraestructura en la nube con AWS Lambda y DynamoDB.**
- **Automatizar despliegues y mantenimiento** con GitHub Actions y AWS CDK.

---

âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

âœ… **Ejecutar API REST de manera eficiente en la nube.**  
âœ… **Escalar automÃ¡ticamente sin intervenciÃ³n del usuario.**  
âœ… **Desplegarse sin configuraciÃ³n manual.**  

âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

```python
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

from mangum import Mangum

âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.


@app.get("/status")
async def status():
    return {"status": "OK", "service": "Medical-RAGArch-System"}

handler = Mangum(app)
```

---

## ğŸ”¹ 2ï¸âƒ£ OptimizaciÃ³n de AWS Lambda y DynamoDB
El sistema ahora implementa **optimizaciÃ³n avanzada en AWS Lambda y DynamoDB**, incluyendo:
âœ… **Compatibilidad con arquitectura ARM64 (`aarch64`)** para mejorar eficiencia.  
âœ… **Uso de DynamoDB DAX** para consultas mÃ¡s rÃ¡pidas.  
âœ… **ActivaciÃ³n de Adaptive Capacity en DynamoDB** para escalado dinÃ¡mico.  
âœ… **Cache en API Gateway** para mejorar tiempos de respuesta.  
âœ… **ImplementaciÃ³n automÃ¡tica de SnapStart en AWS Lambda** para reducir latencia.  

ğŸ”¹ **Ejemplo de configuraciÃ³n automÃ¡tica de SnapStart en AWS Lambda:**  
```python
import boto3

lambda_client = boto3.client("lambda")
response = lambda_client.update_function_configuration(
    FunctionName="MedicalRAGLambda",
    SnapStart={"ApplyOn": "PublishedVersions"}
)
print("SnapStart Enabled:", response)
```

---

## ğŸ”¹ 3ï¸âƒ£ PersonalizaciÃ³n de NLP (Procesamiento de Lenguaje Natural)
Ahora el sistema permite **configurar dinÃ¡micamente** el procesamiento de lenguaje natural.  
âœ… **Ajuste de modelos NLP desde un archivo JSON.**  
âœ… **ConfiguraciÃ³n de longitud de resumen.**  
âœ… **OpciÃ³n de habilitar/deshabilitar muestreo (`do_sample`).**  

ğŸ”¹ **Archivo de configuraciÃ³n `config/nlp_config.json`:**  
```json
{
    "model_name": "facebook/bart-large-cnn",
    "max_length": 150,
    "min_length": 50,
    "do_sample": false
}
```

---

## ğŸ”¹ 4ï¸âƒ£ IntegraciÃ³n de WebSockets con AWS Lambda
Se ha mejorado el soporte para **WebSockets en AWS Lambda**, lo que permite:  
âœ… **ComunicaciÃ³n en tiempo real sin configuraciÃ³n manual.**  
âœ… **Compatibilidad con API Gateway y escalado automÃ¡tico.**  
âœ… **Uso sin costos obligatorios (solo consumo segÃºn trÃ¡fico).**  

âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

```python
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

from mangum import Mangum

âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.


class ConnectionManager:
    def __init__(self):
        self.active_connections = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def send_message(self, message: str):
        for connection in self.active_connections:
            await connection.send_text(message)

manager = ConnectionManager()

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    try:
        while True:
            data = await websocket.receive_text()
            await manager.send_message(f"Mensaje: {data}")
    except WebSocketDisconnect:
        manager.disconnect(websocket)

handler = Mangum(app)
```

---

## âœ… **ConclusiÃ³n**
Este sistema ha sido actualizado para incluir:  
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

âœ… **OptimizaciÃ³n avanzada de DynamoDB y Lambda.**  
âœ… **PersonalizaciÃ³n de NLP sin tocar el cÃ³digo.**  
âœ… **WebSockets eficientes y sin costos ocultos.**  

---


---

## ğŸ”¹ **AutomatizaciÃ³n de Seguridad con AWS Secrets Manager**

Este sistema ahora **gestiona automÃ¡ticamente claves de cifrado** mediante **AWS Secrets Manager**, mejorando la seguridad sin intervenciÃ³n del usuario.

### ğŸ“Œ **1ï¸âƒ£ Â¿CÃ³mo Funciona?**

- **`aws/secrets_manager.py`** crea y recupera claves automÃ¡ticamente en AWS Secrets Manager.
- **`config/aes_config.py`** obtiene la clave AES-256 de AWS en lugar de almacenarla en el cÃ³digo.  
- **`config/_config.py`** obtiene la clave  automÃ¡ticamente sin intervenciÃ³n del usuario.

### ğŸ“Œ **2ï¸âƒ£ ConfiguraciÃ³n AutomÃ¡tica**

La primera vez, ejecuta este comando para inicializar los secretos en AWS:  
```bash
python aws/secrets_manager.py
```

Esto **crearÃ¡ automÃ¡ticamente las claves en AWS Secrets Manager** y estarÃ¡n disponibles para el sistema.

---

## ğŸ”¹ **OptimizaciÃ³n del Despliegue en AWS Lambda**

El despliegue en AWS Lambda ahora es **mÃ¡s rÃ¡pido y eficiente**, gracias a la optimizaciÃ³n en la instalaciÃ³n de dependencias.

### ğŸ“Œ **1ï¸âƒ£ Â¿QuÃ© CambiÃ³?**

- **Ahora usa `--prefer-binary` en la instalaciÃ³n de dependencias** para evitar errores con paquetes sin binarios precompilados.
- **Se ha actualizado `.github/workflows/deploy.yml`** para optimizar el tamaÃ±o del paquete de despliegue.

### ğŸ“Œ **2ï¸âƒ£ Desplegar en AWS AutomÃ¡ticamente**

Para desplegar en AWS Lambda sin intervenciÃ³n manual, solo haz un `push` al repositorio:  
```bash
git push origin main
```

Esto activarÃ¡ **GitHub Actions** y el sistema se actualizarÃ¡ automÃ¡ticamente en AWS.

---

## ğŸ”¹ **UbicaciÃ³n de Archivos Modificados**

| Archivo | UbicaciÃ³n |
|---------|----------|
| `secrets_manager.py` | `aws/secrets_manager.py` |
| `aes_config.py` | `config/aes_config.py` |
| `_config.py` | `config/_config.py` |
| `deploy.yml` | `.github/workflows/deploy.yml` |

Estos cambios garantizan **mÃ¡s seguridad, transparencia y eficiencia** en el despliegue del sistema.



## ğŸ”¥ ActualizaciÃ³n: IntegraciÃ³n de Streamlit y DynamoDB

### ğŸ†• Cambios recientes en esta versiÃ³n:
1. **Nuevo Frontend en Streamlit (`frontend/streamlit_interface.py`)**
   - **AutenticaciÃ³n en ChatGPT "Chat"** con opciÃ³n para cuentas gratuitas y de pago.
   - **Carga de documentos mÃ©dicos con almacenamiento en DynamoDB.**
   - **SelecciÃ³n de prompts sin mostrar su estructura interna.**
   - **InteracciÃ³n con el backend y redirecciÃ³n de consultas.**

2. **Backend actualizado (`api/main.py` y `api/dynamodb_handler.py`)**
   - **Manejo de almacenamiento y recuperaciÃ³n de documentos en DynamoDB.**
   - **Endpoints para interactuar con la interfaz Streamlit.**

3. **Prompt modificado para la nueva arquitectura.**

4. **ActualizaciÃ³n de `requirements.txt`** (sin alterar el orden original).
   - **Se agregaron `prophet` y `redis` solo si no estaban ya presentes.**

### ğŸš€ CÃ³mo Ejecutarlo
1. **Instalar dependencias:**  
   ```bash
   pip install -r requirements.txt
   ```
âœ… **Punto de ConexiÃ³n en AWS Lambda:**
- La conexiÃ³n con los modelos de IA se realiza directamente a travÃ©s de AWS Lambda.
- FastAPI **ya no se usa** como punto de conexiÃ³n dentro de AWS Lambda.

   ```bash
   uvicorn api.main:app --host 0.0.0.0 --port 8000
   ```
3. **Ejecutar Streamlit:**  
   ```bash
   streamlit run frontend/streamlit_interface.py
   ```

âš ï¸ **Nota:** Se recomienda probar en un entorno real para validar `prophet` y `redis` correctamente.


## ğŸ”¥ IntegraciÃ³n AutomÃ¡tica con ChatGPT "Chat"

### ğŸ†• Nueva Funcionalidad:
- **Inicio de sesiÃ³n automÃ¡tico en ChatGPT "Chat"** sin intervenciÃ³n del usuario.
- **EnvÃ­o y recepciÃ³n de mensajes a ChatGPT "Chat"** mediante Selenium.
- **Guardado y reutilizaciÃ³n de sesiÃ³n con cookies** para evitar mÃºltiples inicios de sesiÃ³n.
- **Descarga automÃ¡tica de ChromeDriver** sin requerir configuraciÃ³n manual.

### ğŸš€ CÃ³mo Usarlo
1. **Instalar dependencias:**  
   ```bash
   pip install -r requirements.txt
   ```

2. **Ejecutar la automatizaciÃ³n de ChatGPT:**  
   ```bash
   streamlit run frontend/chatgpt_automation.py
   ```

3. **Iniciar sesiÃ³n con tu cuenta de ChatGPT "Chat".**  
4. **Escribir mensajes en la interfaz y recibir respuestas automÃ¡ticamente.**  

âš ï¸ **Nota:** AsegÃºrate de que tu cuenta de ChatGPT "Chat" estÃ¡ activa antes de usar esta funcionalidad.


## ğŸ”¥ IntegraciÃ³n de Prompts en la Interfaz

### ğŸ†• Nueva Funcionalidad:
- **Carga automÃ¡tica de los prompts guardados en el sistema** (`scripts/prompts.json`).
- **SelecciÃ³n de prompts desde la interfaz de Streamlit.**
- **VisualizaciÃ³n del prompt elegido sin mostrar su estructura interna.**
- **InteracciÃ³n con ChatGPT "Chat" dentro de la interfaz.**
- **OpciÃ³n para subir documentos mÃ©dicos y almacenarlos en DynamoDB.**

### ğŸš€ CÃ³mo Usarlo
1. **Instalar dependencias:**  
   ```bash
   pip install -r requirements.txt
   ```

2. **Ejecutar la interfaz de usuario:**  
   ```bash
   streamlit run frontend/streamlit_interface.py
   ```

3. **Seleccionar un prompt desde la interfaz de Streamlit.**  
4. **Responder las indicaciones de ChatGPT a travÃ©s de la interfaz.**  
5. **Subir documentos mÃ©dicos si el prompt lo requiere.**  

âš ï¸ **Nota:** AsegÃºrate de ejecutar `scripts/update_prompts.py` antes para actualizar los prompts desde GitHub.


---

## âš ï¸ **IMPORTANTE: Uso recomendado con ChatGPT en modo chat**

**Razones por las que se recomienda esta opciÃ³n:**

âœ… **Funciones avanzadas exclusivas**:  
- Esto permite un mejor anÃ¡lisis de documentos y biomarcadores.  

âœ… **Posibilidad de uso gratuito**:  

ğŸ“Œ **RecomendaciÃ³n**: Si deseas usar este sistema sin costo, utiliza **ChatGPT en modo chat** en lugar de la API.  

---

## ğŸ”¹ **ElecciÃ³n de IA y Modelos**

Ahora puedes seleccionar **quÃ© IA deseas usar** para procesar consultas mÃ©dicas.  
Por defecto, se recomienda **ChatGPT en modo chat** por sus funciones avanzadas y acceso gratuito.  

### âœ… **Opciones Disponibles**
| IA | Modelos Disponibles | Gratis | Notas |
|----|--------------------|--------|-------|
| **ChatGPT (Modo Chat)** | GPT-4 Turbo (Recomendado), GPT-4, GPT-3.5 | âœ… SÃ­ | Acceso gratuito con cuenta Free |
| **Gemini (Google)** | Gemini 1.5 (Beta), Gemini 1.0 | âœ… SÃ­ | âš ï¸ Menos contexto que ChatGPT |
| **Claude (Anthropic)** | Claude 3 Opus, Claude 2 | âŒ No | âš ï¸ Requiere cuenta paga |
| **Mistral AI** | Mistral-7B, Mixtral | âŒ No | âš ï¸ Mejor para programaciÃ³n que medicina |

ğŸ“Œ **RecomendaciÃ³n:** Si deseas usar el sistema **gratis**, elige **ChatGPT (Modo Chat) o Gemini**.  

---

### ğŸ“Œ **CÃ³mo Funciona la SelecciÃ³n de IA**
1. **Selecciona la IA** en la interfaz.  
2. **Elige el modelo** disponible para esa IA.  
3. **Si una IA no estÃ¡ implementada**, aparecerÃ¡ un aviso.  
4. **Si la IA requiere pago, se mostrarÃ¡ una advertencia.**  

ğŸ“¢ **Si una IA no ofrece las mismas funciones que ChatGPT en modo chat, se indicarÃ¡ en la interfaz.**  

---

## ğŸ”¹ **Modelos de IA Gratuitos y de Pago**

El sistema ahora permite seleccionar **tanto modelos gratuitos como de pago** en varias IAs.  
Si tienes una cuenta premium en alguna de ellas, puedes aprovechar modelos mÃ¡s avanzados.

### âœ… **Opciones Disponibles**
| IA | Modelos Gratuitos | Modelos de Pago | Notas |
|----|------------------|----------------|-------|
| **ChatGPT (Modo Chat)** | GPT-4 Turbo, GPT-3.5 | GPT-4 ğŸ”’ | Recomendado por funciones avanzadas |
| **Gemini (Google)** | Gemini 1.5, Gemini 1.0 | âŒ No disponible | âš ï¸ Menos contexto que ChatGPT |
| **Claude (Anthropic)** | Claude 2 | Claude 3 Opus ğŸ”’ | âš ï¸ Menor soporte en anÃ¡lisis mÃ©dicos |
| **Mistral AI** | Mistral-7B | Mixtral ğŸ”’ | âš ï¸ MÃ¡s orientado a programaciÃ³n |

ğŸ“Œ **RecomendaciÃ³n:** Si no tienes cuenta premium, usa **ChatGPT en modo chat o Gemini 1.5**.  

---

## ğŸ”’ **AutenticaciÃ³n Segura y ProtecciÃ³n de Credenciales**

Para modelos de pago, el usuario debe ingresar su **API Key**.  
ğŸ“Œ **El sistema protege las credenciales con cifrado AES-256** antes de enviarlas al backend.  

âœ… **Medidas de seguridad implementadas:**  
- **Las credenciales se cifran antes de su uso.**  
- **No se almacenan en texto plano en el frontend.**  
- **Se desencriptan solo en la sesiÃ³n activa del usuario.**  

ğŸ“¢ **Advertencia:** Nunca compartas tu API Key con terceros.  

---

## ğŸ”¹ **IAs Compatibles: Modelos Gratuitos y de Pago**

Ahora el sistema soporta mÃºltiples IAs con sus versiones **gratuitas y premium**.  
Si tienes cuenta premium en alguna IA, puedes aprovechar modelos mÃ¡s avanzados.  

### âœ… **Opciones Disponibles**
| IA | Modelos Gratuitos | Modelos de Pago | Notas |
|----|------------------|----------------|-------|
| **ChatGPT (Modo Chat)** | GPT-4 Turbo, GPT-3.5 | GPT-4 ğŸ”’ | Recomendado por funciones avanzadas |
| **Gemini (Google)** | Gemini 1.5, Gemini 1.0 | âŒ No disponible | âš ï¸ Menos contexto que ChatGPT |
| **Claude (Anthropic)** | Claude 2 | Claude 3 Opus ğŸ”’ | âš ï¸ Menor soporte en anÃ¡lisis mÃ©dicos |
| **Mistral AI** | Mistral-7B | Mixtral ğŸ”’ | âš ï¸ MÃ¡s orientado a programaciÃ³n |
| **Llama (Meta AI)** | Llama 3, Llama 2 | Llama 3-70B ğŸ”’ | âš ï¸ Menos optimizado para lenguaje mÃ©dico |
| **Cohere AI** | Command-R | Command-R+ ğŸ”’ | âš ï¸ Limitado en consultas mÃ©dicas avanzadas |

ğŸ“Œ **RecomendaciÃ³n:** Si no tienes cuenta premium, usa **ChatGPT en modo chat, Gemini o Llama 3**.  

---

## ğŸ“Œ **ComparaciÃ³n con ChatGPT**

ğŸ“¢ **ChatGPT sigue siendo la opciÃ³n recomendada** porque:  
- **Tiene mejor acceso a funciones avanzadas en modo chat.**  
- **Puede usarse gratis sin restricciones significativas.**  
- **Soporta consultas mÃ©dicas mejor que otras IAs.**  

Si eliges otra IA, ten en cuenta que algunas pueden tener **menos contexto** o **menor precisiÃ³n** en temas mÃ©dicos.  
---

## ğŸ”¹ Mejoras y Nuevas Funcionalidades en esta VersiÃ³n

### âœ… RecuperaciÃ³n Flexible de Documentos en DynamoDB
Ahora se pueden solicitar **cualquier tipo de documentos almacenados** en DynamoDB, incluyendo:
- **AnalÃ­ticas mÃ©dicas**
- **DiagnÃ³sticos clÃ­nicos**
- **Informes mÃ©dicos**

ğŸ“Œ **Ejemplo de uso:**  
Para obtener los Ãºltimos **5 informes mÃ©dicos**, la consulta serÃ­a:
```
GET /retrieve_documents/?document_type=informe_medico&limit=5
```

### âœ… ComparaciÃ³n de Biomarcadores en Backend
Ahora se pueden solicitar biomarcadores de mÃºltiples maneras:
- **Solo fuera de rango.**
- **En rango y fuera de rango.**
- **Biomarcadores complementarios para evaluar evoluciÃ³n.**

ğŸ“Œ **Ejemplo de uso:**  
Para analizar biomarcadores incluyendo los que estÃ¡n dentro del rango y complementarios:
```
POST /analyze_biomarkers/
{
    "documents": [...],
    "include_complementary": true,
    "include_in_range": true
}
```

### âœ… Frontend Optimizado para ChatGPT
El frontend ahora:
- Permite elegir **quÃ© biomarcadores enviar a ChatGPT.**
- Permite recuperar cualquier tipo de documento desde DynamoDB.
- Permite filtrar los biomarcadores que se envÃ­an a ChatGPT, asegurando respuestas mÃ¡s precisas.

ğŸ“Œ **Ejemplo de flujo completo:**
1. **El usuario pregunta:** "CompÃ¡rame mis Ãºltimas 5 analÃ­ticas e identifica tendencias de glucosa."
2. **El backend obtiene los datos y los analiza.**
3. **Solo los datos relevantes son enviados a ChatGPT.**

---

### ğŸ”§ Posibles Ajustes y Configuraciones
1. **Si DynamoDB cambia de nombre**, actualizarlo en `.env` y `api/dynamodb_handler.py`.
2. **Si se requieren mÃ¡s tipos de documentos**, simplemente enviarlos en `document_type`.
3. **Si ChatGPT necesita mÃ¡s contexto**, modificar `frontend/chatgpt_automation.py` para ajustar el prompt.


## ğŸš€ ImplementaciÃ³n de APIs de IA en Medical-RAGArch-System

Se ha implementado soporte para mÃºltiples IAs en el sistema, asegurando compatibilidad tanto con **modo chat (cuando es posible) como con APIs**.  
Las siguientes IAs han sido integradas correctamente:

| **IA**       | **Modo Chat** | **API (Pago)** | **Notas** |
|-------------|--------------|----------------|-----------|
| **Gemini (Google)** | âœ… SÃ­ | âœ… SÃ­ | Gemini 1.5 soportado. |
| **Claude (Anthropic)** | âŒ No | âœ… SÃ­ | Solo API disponible. |
| **Mistral AI** | âŒ No | âœ… SÃ­ | Solo API disponible. |
| **Llama (Meta AI)** | âŒ No | âœ… SÃ­ | Solo API disponible. |
| **Cohere AI** | âŒ No | âœ… SÃ­ | Solo API disponible. |
| **DeepSeek AI** | âœ… SÃ­ | âœ… SÃ­ | Nuevo soporte aÃ±adido. |

### ğŸ“Œ CaracterÃ­sticas clave de la implementaciÃ³n:
1. **Compatibilidad con cuentas gratuitas y de pago**: Se verifica si el usuario tiene cuenta gratuita o premium antes de usar la API.  
2. **Modo chat habilitado donde es posible**: Para maximizar capacidades, el sistema usa modo chat en IAs que lo soportan.  
3. **DeepSeek AI ahora es compatible**: Se ha aÃ±adido soporte completo para DeepSeek.  
4. **ConfiguraciÃ³n de claves API**: Cada IA requiere una clave API en las variables de entorno correspondientes.  

### ğŸ”§ **CÃ³mo configurar las claves API**:
Debes aÃ±adir tus claves API en las variables de entorno antes de ejecutar el sistema. Ejemplo en Linux:
```bash
export GEMINI_REMOVED_SECRET
export ANTHROPIC_REMOVED_SECRET
export MISTRAL_REMOVED_SECRET
export LLAMA_REMOVED_SECRET
export COHERE_REMOVED_SECRET
export DEEPSEEK_REMOVED_SECRET
```
Si usas Windows, puedes configurarlas con:
```powershell
$env:GEMINI_REMOVED_SECRET
```

### ğŸ›  **Ejemplo de uso en cÃ³digo**
Para usar cualquiera de estas IAs, simplemente importa su clase y haz una consulta:
```python

print(response)
```

---

## ğŸ”’ ImplementaciÃ³n de Zero Trust con CachÃ© en Redis Cloud Essentials y EFS
- **Ahora la autenticaciÃ³n sigue un modelo de Zero Trust con doble capa de cachÃ© (Redis + EFS).**
- **Redis Cloud Essentials almacena tokens temporalmente para reducir latencia.**
- **EFS se usa como respaldo para mantener tokens de sesiÃ³n persistentes.**

### ğŸ› ï¸ CÃ³mo Funciona
- Al recibir una solicitud, primero se revisa la cachÃ© en Redis Cloud Essentials.
- Si el usuario ya ha sido autenticado recientemente, se usa la cachÃ©.
- Si no, se valida la identidad en tiempo real y se almacena el resultado en Redis y EFS.

### ğŸ”„ Beneficios de la ImplementaciÃ³n
- **Mayor seguridad:** Zero Trust garantiza que cada acceso sea validado dinÃ¡micamente.
- **Menor latencia:** Redis Cloud Essentials acelera la autenticaciÃ³n sin comprometer seguridad.
- **Persistencia:** Redis maneja datos en memoria y EFS asegura sesiones entre reinicios.

### ğŸ”§ ConfiguraciÃ³n Necesaria
- Se debe configurar Redis Cloud Essentials con `REDIS_HOST` y `REDIS_PASSWORD`.
- AWS Lambda ya estÃ¡ preparado para conectar con EFS (`/mnt/efs/cache`).
- No se requieren claves API, la autenticaciÃ³n se maneja con IAM y contexto dinÃ¡mico.


## ğŸ“Œ ActualizaciÃ³n de Integraciones y Seguridad

### âœ… **1. IntegraciÃ³n de `sources_config.yaml` en mÃ³dulos clave**
Se ha implementado la jerarquizaciÃ³n y validaciÃ³n de fuentes en:

- **`intelligent_context.py`** â†’ Ahora utiliza `sources_config.yaml` para aplicar reglas de fuentes permitidas en el anÃ¡lisis de contexto.
- **`supplement_interaction_validation.py`** â†’ Ahora valida los suplementos usando Ãºnicamente fuentes permitidas segÃºn la jerarquizaciÃ³n.

Ambos mÃ³dulos ahora garantizan que solo se utilicen **fuentes confiables** definidas en la configuraciÃ³n.

---

### âœ… **2. VerificaciÃ³n de Seguridad Final**
Se realizÃ³ un **anÃ¡lisis exhaustivo del cÃ³digo** y se corrigieron los siguientes aspectos:

- ğŸ”’ **EliminaciÃ³n de todas las referencias a JWT y autenticaciÃ³n insegura.**
- ğŸ”’ **MigraciÃ³n completa a TLS 1.3 en todos los mÃ³dulos.**
- ğŸ”’ **CorrecciÃ³n de `requirements.txt` agregando dependencias faltantes (AWS CDK, Dask, Matplotlib, Plotly).**
- ğŸ”’ **VerificaciÃ³n de reglas de fuentes y almacenamiento seguro de datos.**

El sistema ahora cumple con **los mÃ¡s altos estÃ¡ndares de seguridad y privacidad**.

---

### âœ… **3. Funcionalidad mejorada en carga y anÃ¡lisis de analÃ­ticas**
- ğŸ¥ **El sistema ya reconoce automÃ¡ticamente las "3 Ãºltimas analÃ­ticas"** y las utiliza en los anÃ¡lisis.
- ğŸ“Š **Los mÃ³dulos de generaciÃ³n de reportes y validaciÃ³n de suplementos ahora solo trabajan con fuentes confiables.**
- âš¡ **No se requieren configuraciones adicionales para estas funcionalidades.**

---

ğŸ”¹ **Todo estÃ¡ documentado y listo.** El sistema ahora **es mÃ¡s seguro, eficiente y estructurado**.
